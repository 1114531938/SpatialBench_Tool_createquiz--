egoexo4d_take_names = [
    "cmu_bike06_4", "cmu_bike10_2", "cmu_bike09_4", "cmu_bike10_3", "cmu_bike10_4",
    "indiana_bike_05_5", "indiana_bike_15_14", "indiana_bike_05_4", "indiana_bike_14_8", "indiana_bike_08_2",
    "georgiatech_bike_10_2", "georgiatech_bike_13_11", "georgiatech_bike_12_8", "georgiatech_bike_10_6", "georgiatech_bike_13_9",
    "iiith_soccer_022_2", "iiith_soccer_043_2", "iiith_soccer_043_8", "iiith_soccer_022_3", "iiith_soccer_008_2",
    "unc_soccer_09-22-23_01_22", "unc_soccer_09-22-23_01_23", "unc_soccer_09-21-23_01_28", "unc_soccer_09-22-23_01_25", "unc_soccer_09-21-23_01_33",
    "utokyo_soccer_8000_44_45_2", "utokyo_soccer_8000_44_45_4", "utokyo_soccer_8000_17_6", "utokyo_soccer_8000_17_2", "utokyo_soccer_8000_17_4",
    "fair_cooking_09_2", "fair_cooking_09_8", "fair_cooking_09_6", "indiana_cooking_19_2", "indiana_cooking_25_2",
    "indiana_cooking_25_3", "georgiatech_cooking_03_01_2", "georgiatech_cooking_12_02_2", "georgiatech_cooking_03_03_4", "iiith_cooking_70_6",
    "iiith_cooking_129_2", "iiith_cooking_53_2", "minnesota_cooking_040_2", "minnesota_cooking_040_4", "minnesota_cooking_040_6",
    "nus_cooking_09_2", "nus_cooking_13_2", "nus_cooking_13_4", "upenn_0630_Cooking_4_2", "upenn_0713_Cooking_2_2",
    "upenn_0711_Cooking_4_2", "utokyo_omelet_5_1001_2", "utokyo_omelet_3_1001_2", "utokyo_omelet_3_1001_4", "utokyo_salad_10_1018_2",
    "utokyo_salad_10_1018_4", "utokyo_sushi_10_1008_2", "utokyo_sushi_1_1008_4", "utokyo_sushi_10_1008_4", "uniandes_cooking_005_12",
    "uniandes_cooking_004_2", "uniandes_cooking_003_2", "sfu_cooking024_2", "sfu_cooking027_7", "sfu_cooking024_6",
    "georgiatech_covid_17_7", "georgiatech_covid_17_9", "georgiatech_covid_15_2", "nus_covidtest_26_2", "nus_covidtest_23_2",
    "nus_covidtest_63_1", "sfu_covid_011_2", "sfu_covid_008_6", "sfu_covid_004_10", "utokyo_pcr_2001_22_2",
    "utokyo_pcr_2001_22_4", "utokyo_pcr_2001_27_6", "minnesota_rockclimbing_043_10", "minnesota_rockclimbing_030_6", "minnesota_rockclimbing_042_8",
    "minnesota_rockclimbing_021_26", "minnesota_rockclimbing_042_2", "minnesota_rockclimbing_043_8", "minnesota_rockclimbing_021_22", "minnesota_rockclimbing_030_4",
    "minnesota_rockclimbing_021_30", "minnesota_rockclimbing_042_4", "uniandes_bouldering_032_5", "uniandes_bouldering_026_87", "uniandes_bouldering_012_47",
    "uniandes_bouldering_030_6", "uniandes_bouldering_030_73", "uniandes_bouldering_032_69", "uniandes_bouldering_024_62", "uniandes_bouldering_030_66",
    "uniandes_bouldering_030_65", "uniandes_bouldering_032_7", "nus_cpr_23_2", "nus_cpr_33_3", "nus_cpr_01_1",
    "nus_cpr_06_1", "nus_cpr_01_2", "nus_cpr_49_1", "nus_cpr_03_2", "utokyo_cpr_2005_22_2",
    "utokyo_cpr_2005_24_2", "utokyo_cpr_2005_27_2", "sfu_basketball_10_11", "sfu_basketball_01_31", "sfu_basketball_04_21",
    "sfu_basketball_04_25", "sfu_basketball_06_8", "unc_basketball_03-09-23_02_39", "unc_basketball_03-16-23_01_5", "unc_basketball_03-31-23_01_37",
    "unc_basketball_02-24-23_01_14", "unc_basketball_03-31-23_01_24", "uniandes_basketball_001_16", "uniandes_basketball_001_18", "uniandes_basketball_001_40",
    "uniandes_basketball_003_54", "uniandes_basketball_004_19", "uniandes_dance_017_49", "uniandes_dance_015_10", "uniandes_dance_024_33",
    "uniandes_dance_018_13", "uniandes_dance_024_21", "upenn_0730_Partner_Dance_1_2_7", "upenn_0707_Dance_3_8", "upenn_0720_Dance_1_3",
    "upenn_0707_Dance_3_5", "upenn_0720_Dance_1_2", "upenn_0727_Dance_1_3", "upenn_0707_Dance_2_5", "upenn_0707_Dance_1_4",
    "upenn_0707_Dance_2_2", "upenn_0707_Dance_1_3"
]

youtube_ids = [
    "youtube_001", "youtube_002", "youtube_003", "youtube_004", "youtube_005", "youtube_006", "youtube_007", "youtube_008", "youtube_009", "youtube_010",
    "youtube_011", "youtube_012", "youtube_013", "youtube_014", "youtube_015", "youtube_016", "youtube_017", "youtube_018", "youtube_019", "youtube_020",
    "youtube_021", "youtube_022", "youtube_023", "youtube_024", "youtube_025", "youtube_026", "youtube_027", "youtube_028", "youtube_029", "youtube_030",
    "youtube_031", "youtube_032", "youtube_033", "youtube_034", "youtube_035", "youtube_036", "youtube_037", "youtube_038", "youtube_039", "youtube_040",
    "youtube_041", "youtube_042", "youtube_043", "youtube_044", "youtube_045", "youtube_046", "youtube_047", "youtube_048", "youtube_049", "youtube_050",
    "youtube_051", "youtube_052", "youtube_053", "youtube_054", "youtube_055", "youtube_056", "youtube_057", "youtube_058", "youtube_059", "youtube_060",
    "youtube_061", "youtube_062", "youtube_063", "youtube_064", "youtube_065", "youtube_066", "youtube_067", "youtube_068", "youtube_069", "youtube_070",
    "youtube_071", "youtube_072", "youtube_073", "youtube_074", "youtube_075", "youtube_076", "youtube_077", "youtube_078", "youtube_079", "youtube_080",
    "youtube_081", "youtube_082", "youtube_083", "youtube_084", "youtube_085", "youtube_086", "youtube_087", "youtube_088", "youtube_089", "youtube_090",
    "youtube_091", "youtube_092", "youtube_093", "youtube_094", "youtube_095", "youtube_096", "youtube_097", "youtube_098", "youtube_099", "youtube_100",
    "youtube_101", "youtube_102", "youtube_103", "youtube_104", "youtube_105", "youtube_106", "youtube_107", "youtube_108", "youtube_109", "youtube_110",
    "youtube_111", "youtube_112", "youtube_113", "youtube_114", "youtube_115", "youtube_116", "youtube_117", "youtube_118", "youtube_119", "youtube_120",
    "youtube_121", "youtube_122", "youtube_123", "youtube_124", "youtube_125", "youtube_126", "youtube_127", "youtube_128", "youtube_129", "youtube_130",
    "youtube_131", "youtube_132", "youtube_133", "youtube_134", "youtube_135", "youtube_136", "youtube_137", "youtube_138", "youtube_139", "youtube_140",
    "youtube_141", "youtube_142", "youtube_143", "youtube_144", "youtube_145", "youtube_146", "youtube_147", "youtube_148", "youtube_149", "youtube_150",
    "youtube_151", "youtube_152", "youtube_153", "youtube_154", "youtube_155", "youtube_156", "youtube_157", "youtube_158", "youtube_159", "youtube_160",
    "youtube_161", "youtube_162", "youtube_163", "youtube_164", "youtube_165", "youtube_166", "youtube_167", "youtube_168", "youtube_169", "youtube_170",
    "youtube_171", "youtube_172", "youtube_173", "youtube_174", "youtube_175", "youtube_176", "youtube_177", "youtube_178", "youtube_179", "youtube_180",
    "youtube_181", "youtube_182", "youtube_183", "youtube_184", "youtube_185", "youtube_186", "youtube_187", "youtube_188", "youtube_189", "youtube_190",
    "youtube_191", "youtube_192", "youtube_193", "youtube_194", "youtube_195", "youtube_196", "youtube_197", "youtube_198", "youtube_199", "youtube_200"
]

hd_epic_samples = [
    "P01-01", "P01-02", "P01-03", "P01-04", "P01-05", "P01-06", "P01-07", "P01-08", "P01-09", "P01-10",
    "P01-11", "P02-01", "P02-02", "P02-03", "P02-04", "P02-05", "P02-06", "P02-07", "P02-08", "P02-09",
    "P02-10", "P02-11", "P03-01", "P03-02", "P03-03", "P03-04", "P03-05", "P03-06", "P03-07", "P03-08",
    "P03-09", "P03-10", "P03-11", "P04-01", "P04-02", "P04-03", "P04-04", "P04-05", "P04-06", "P04-07",
    "P04-08", "P04-09", "P04-10", "P04-11", "P05-01", "P05-02", "P05-03", "P05-04", "P05-05", "P05-06",
    "P05-07", "P05-08", "P05-09", "P05-10", "P05-11", "P06-01", "P06-02", "P06-03", "P06-04", "P06-05",
    "P06-06", "P06-07", "P06-08", "P06-09", "P06-10", "P06-11", "P07-01", "P07-02", "P07-03", "P07-04",
    "P07-05", "P07-06", "P07-07", "P07-08", "P07-09", "P08-01", "P08-02", "P08-03", "P08-04", "P08-05",
    "P08-06", "P08-07", "P08-08", "P08-09", "P08-10", "P08-11", "P09-01", "P09-02", "P09-03", "P09-04",
    "P09-05", "P09-06", "P09-07", "P09-08", "P09-09", "P09-10", "P09-11", "P01-12", "P01-13", "P01-14"
]

#!/usr/bin/env python3
"""
视频文件检查工具 - 检查QA候选文件中的视频是否本地存在
"""

import json
import os
import glob
import csv
import zipfile
import shutil
from typing import Set, List
from huggingface_hub import hf_hub_download


def scan_qa_files(qa_dir: str) -> list:
    """扫描指定目录下所有包含qacandidate的JSON文件，提取video_name"""
    video_names = []
    pattern = os.path.join(qa_dir, "*qacandidate*.json")
    
    for file_path in sorted(glob.glob(pattern)):  # 确保文件顺序一致
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            for segment_data in data.values():
                if isinstance(segment_data, dict) and 'video_name' in segment_data:
                    video_name = segment_data['video_name']
                    if video_name not in video_names:  # 避免重复
                        video_names.append(video_name)
    
    return video_names


def check_local_videos(video_names: list, cache_dir: str) -> dict:
    """检查视频文件是否在本地缓存目录中存在且完整"""
    results = {}
    for video_name in video_names:
        video_folder = os.path.join(cache_dir, video_name)
        
        # 检查目录是否存在
        if not os.path.exists(video_folder):
            results[video_name] = False
            continue
        
        # 进一步检查内容是否完整
        video_type = get_video_type(video_name)
        if video_type in ["youtube", "activitynet"]:
            # MP4文件检查
            video_file = os.path.join(video_folder, f"{video_name}.mp4")
            results[video_name] = os.path.exists(video_file) and os.path.getsize(video_file) > 0
        else:
            # ZIP解压文件检查
            try:
                files = os.listdir(video_folder)
                # 只统计视频文件和有意义的文件，过滤掉缓存文件
                valid_files = []
                for f in files:
                    # 跳过隐藏文件、临时文件和缓存目录
                    if (not f.startswith('.') and 
                        not f.endswith(('.tmp', '.temp', '.lock')) and
                        f not in ['__pycache__', 'Thumbs.db']):
                        valid_files.append(f)
                results[video_name] = len(valid_files) > 0
            except Exception:
                results[video_name] = False
    
    return results


def get_video_type(video_name: str) -> str:
    """根据video_name判断视频类型和所属数据集"""
    # 检查是否在预定义的数据集列表中
    if video_name in egoexo4d_take_names:
        return "egoexo4d"
    elif video_name in youtube_ids:
        return "youtube"
    elif video_name in hd_epic_samples:
        return "hd-epic"
    else:
        return "activitynet"


def download_single_video(video_name: str, cache_dir: str) -> bool:
    """下载单个视频文件到本地缓存目录"""
    target_dir = os.path.join(cache_dir, video_name)
    
    try:
        # 判断视频类型
        video_type = get_video_type(video_name)
        
        # 设置HuggingFace仓库和路径
        repo_id = "GuangsTrip/spatialpredictsource"
        
        if video_type == "youtube":
            # YouTube视频是MP4文件
            file_path = f"videos/youtube/{video_name}.mp4"
            file_extension = ".mp4"
        elif video_type == "activitynet":
            # ActivityNet视频是MP4文件
            file_path = f"videos/activitynet/{video_name}.mp4"
            file_extension = ".mp4"
        else:
            # EgoExo4D和HD-EPIC是ZIP文件
            file_path = f"videos/{video_type}/{video_name}.zip"
            file_extension = ".zip"
        
        print(f"正在下载 {video_name} ({video_type})...")
        
        # 创建目标目录
        os.makedirs(target_dir, exist_ok=True)
        
        # 下载文件到临时目录
        temp_download_dir = os.path.join(target_dir, ".temp_download")
        os.makedirs(temp_download_dir, exist_ok=True)
        
        downloaded_file = hf_hub_download(
            repo_id=repo_id,
            filename=file_path,
            repo_type="dataset",
            cache_dir=temp_download_dir
        )
        
        if file_extension == ".zip":
            # 如果是ZIP文件，解压到目标目录
            print(f"正在解压 {video_name}...")
            with zipfile.ZipFile(downloaded_file, 'r') as zip_ref:
                zip_ref.extractall(target_dir)
        else:
            # 如果是MP4文件，移动到目标目录
            target_file = os.path.join(target_dir, f"{video_name}.mp4")
            
            # 确保目标文件不存在，避免冲突
            if os.path.exists(target_file):
                os.remove(target_file)
            
            # 使用复制+删除的方式，更可靠
            shutil.copy2(downloaded_file, target_file)
            
            # 验证复制是否成功
            if os.path.exists(target_file) and os.path.getsize(target_file) > 0:
                # 删除源文件
                try:
                    os.remove(downloaded_file)
                except Exception:
                    pass  # 忽略删除失败
            else:
                raise Exception("文件复制失败")
        
        # 清理临时下载目录和HuggingFace缓存文件
        if os.path.exists(temp_download_dir):
            shutil.rmtree(temp_download_dir)
        
        # 清理可能存在的其他缓存文件
        _cleanup_cache_files(target_dir)
        
        # 验证下载结果
        if not _verify_download_success(target_dir, video_name, file_extension):
            raise Exception("下载验证失败，文件不完整")
        
        print(f"✓ {video_name} 下载完成")
        return True
        
    except Exception as e:
        print(f"✗ {video_name} 下载失败: {str(e)}")
        
        # 清理失败的目录
        if os.path.exists(target_dir):
            try:
                shutil.rmtree(target_dir)
                print(f"已清理失败的目录: {target_dir}")
            except Exception as cleanup_error:
                print(f"警告: 清理目录失败: {cleanup_error}")
        
        return False


def _cleanup_cache_files(target_dir: str) -> None:
    """清理HuggingFace和其他缓存文件"""
    try:
        for item in os.listdir(target_dir):
            item_path = os.path.join(target_dir, item)
            
            # 删除常见的缓存目录和文件
            if item in ['.cache', '.git', '__pycache__', '.DS_Store', 'Thumbs.db']:
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                else:
                    os.remove(item_path)
            
            # 删除以点开头的隐藏文件和目录（除了视频文件）
            elif item.startswith('.') and not item.endswith(('.mp4', '.avi', '.mov', '.mkv')):
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                else:
                    os.remove(item_path)
            
            # 删除临时文件
            elif item.endswith(('.tmp', '.temp', '.lock')):
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                else:
                    os.remove(item_path)
    except Exception as e:
        # 清理失败不影响主要功能，只记录警告
        print(f"警告: 清理缓存文件时出错: {e}")


def _verify_download_success(target_dir: str, video_name: str, file_extension: str) -> bool:
    """验证下载是否成功"""
    try:
        if file_extension == ".zip":
            # 对于ZIP文件，检查是否有解压后的有效文件
            files = os.listdir(target_dir)
            # 只统计视频文件和有意义的文件，过滤掉缓存文件
            valid_files = []
            for f in files:
                # 跳过隐藏文件、临时文件和缓存目录
                if (not f.startswith('.') and 
                    not f.endswith(('.tmp', '.temp', '.lock')) and
                    f not in ['__pycache__', 'Thumbs.db']):
                    valid_files.append(f)
            return len(valid_files) > 0
        else:
            # 对于MP4文件，检查文件是否存在且大小大于0
            video_file = os.path.join(target_dir, f"{video_name}.mp4")
            
            # 使用绝对路径进行验证
            abs_video_file = os.path.abspath(video_file)
            
            if not os.path.exists(abs_video_file):
                # 检查是否有同名文件但路径不匹配
                try:
                    dir_contents = os.listdir(target_dir)
                    for item in dir_contents:
                        if item == f"{video_name}.mp4":
                            full_path = os.path.join(target_dir, item)
                            return os.path.getsize(full_path) > 0
                except Exception:
                    pass
                return False
            
            file_size = os.path.getsize(abs_video_file)
            return file_size > 0
            
    except Exception:
        return False


def download_missing_videos(video_names: List[str]) -> None:
    """下载缺失的视频文件（预留接口）"""
    # TODO: 实现云端下载逻辑
    pass


def save_results_to_csv(results: dict, video_names: list, output_file: str) -> None:
    """将检查结果保存到CSV文件，保留之前的异常状态"""
    # 读取之前的CSV文件以保留异常状态
    previous_status = {}
    if os.path.exists(output_file):
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    video_name = row['video_name']
                    status = row.get('status', '')
                    # 保留异常状态
                    if status == '下载异常':
                        previous_status[video_name] = status
        except Exception as e:
            print(f"读取之前的CSV文件时出错: {e}")
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['video_name', 'status', 'pick_now'])
        for video_name in video_names:  # 按照原始顺序输出
            exists = results[video_name]
            if exists:
                status = '✓'
            elif video_name in previous_status:
                # 保留之前的异常状态
                status = previous_status[video_name]
            else:
                status = ''
            writer.writerow([video_name, status, ''])


def show_statistics(video_names: list, cache_dir: str, output_csv: str):
    """显示统计信息并保存到CSV"""
    print("正在扫描本地视频...")
    results = check_local_videos(video_names, cache_dir)
    missing_videos = {name for name, exists in results.items() if not exists}
    existing_videos = {name for name, exists in results.items() if exists}
    
    save_results_to_csv(results, video_names, output_csv)
    
    # 统计异常视频数量
    failed_videos = get_failed_videos_from_csv(output_csv)
    
    print("\n" + "="*50)
    print("本地视频统计信息")
    print("="*50)
    print(f"总视频数量: {len(video_names)}")
    print(f"本地已存在: {len(existing_videos)}")
    print(f"缺失视频数: {len(missing_videos)}")
    print(f"下载异常数: {len(failed_videos)}")
    print(f"存在率: {len(existing_videos)/len(video_names)*100:.1f}%")
    print("="*50)
    print(f"详细结果已保存到: {output_csv}")
    print("提示: 您可以编辑CSV文件的'pick_now'列来标记需要下载的视频")
    print("     在需要下载的视频行填入 'x' 或 '1' 即可标记选中")


def read_selected_videos_from_csv(csv_file: str) -> List[str]:
    """从CSV文件中读取用户选中的视频列表"""
    selected_videos = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # 检查pick_now列是否标记为选中（x, 1, true等）
                pick_value = row.get('pick_now', '').strip().lower()
                if pick_value in ['x', '1', 'true', 'yes', '✓']:
                    selected_videos.append(row['video_name'])
    except FileNotFoundError:
        print(f"错误: 找不到CSV文件 {csv_file}")
        print("请先运行统计功能生成CSV文件")
    except Exception as e:
        print(f"读取CSV文件时出错: {str(e)}")
    
    return selected_videos


def update_single_video_status(video_name: str, status: str, csv_file: str) -> None:
    """更新单个视频的状态到CSV文件"""
    if not os.path.exists(csv_file):
        return
    
    try:
        # 读取现有CSV数据
        rows = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['video_name'] == video_name:
                    row['status'] = status
                rows.append(row)
        
        # 写回CSV文件
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            if rows:
                fieldnames = ['video_name', 'status', 'pick_now']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(rows)
        
    except Exception as e:
        print(f"警告: 更新视频 {video_name} 状态时出错: {e}")


def update_csv_after_download(video_list: List[str], success_list: List[str], failed_list: List[str], csv_file: str) -> None:
    """下载完成后更新CSV文件状态"""
    if not os.path.exists(csv_file):
        print(f"警告: CSV文件 {csv_file} 不存在，无法更新状态")
        return
    
    try:
        # 读取现有CSV数据
        rows = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                video_name = row['video_name']
                
                # 更新状态
                if video_name in success_list:
                    row['status'] = '✓'
                elif video_name in failed_list:
                    row['status'] = '下载异常'
                
                # 清除pick_now标记（无论是否在下载列表中）
                row['pick_now'] = ''
                
                rows.append(row)
        
        # 写回CSV文件
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            if rows:
                fieldnames = ['video_name', 'status', 'pick_now']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(rows)
        
        print(f"CSV文件状态已更新: 成功 {len(success_list)} 个, 失败 {len(failed_list)} 个")
        
    except Exception as e:
        print(f"更新CSV文件时出错: {e}")


def get_failed_videos_from_csv(csv_file: str) -> List[str]:
    """从CSV文件中获取状态为"下载异常"的视频列表"""
    failed_videos = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('status', '').strip() == '下载异常':
                    failed_videos.append(row['video_name'])
    except FileNotFoundError:
        print(f"错误: 找不到CSV文件 {csv_file}")
    except Exception as e:
        print(f"读取CSV文件时出错: {str(e)}")
    
    return failed_videos
    
def download_videos_batch(video_list: List[str], cache_dir: str, description: str) -> tuple[List[str], List[str]]:
    """批量下载视频，返回成功和失败的视频列表"""
    if not video_list:
        print(f"没有需要下载的{description}")
        return [], []
    
    print(f"\n开始下载{description} (共{len(video_list)}个)...")
    print("="*50)
    
    success_list = []
    failed_list = []
    csv_file = "./video_download_status.csv"  # 获取CSV文件路径
    
    try:
        for i, video_name in enumerate(video_list, 1):
            print(f"\n[{i}/{len(video_list)}]", end=" ")
            
            try:
                # 检查是否已存在且完整
                video_folder = os.path.join(cache_dir, video_name)
                if os.path.exists(video_folder):
                    # 使用与check_local_videos相同的验证逻辑
                    video_type = get_video_type(video_name)
                    is_complete = False
                    
                    if video_type in ["youtube", "activitynet"]:
                        # MP4文件检查
                        video_file = os.path.join(video_folder, f"{video_name}.mp4")
                        is_complete = os.path.exists(video_file) and os.path.getsize(video_file) > 0
                    else:
                        # ZIP解压文件检查
                        try:
                            files = os.listdir(video_folder)
                            # 只统计视频文件和有意义的文件，过滤掉缓存文件
                            valid_files = []
                            for f in files:
                                if (not f.startswith('.') and 
                                    not f.endswith(('.tmp', '.temp', '.lock')) and
                                    f not in ['__pycache__', 'Thumbs.db']):
                                    valid_files.append(f)
                            is_complete = len(valid_files) > 0
                        except Exception:
                            is_complete = False
                    
                    if is_complete:
                        print(f"跳过 {video_name} (已存在)")
                        # 已存在且完整的视频标记为成功状态
                        success_list.append(video_name)
                        # 立即更新CSV状态
                        update_single_video_status(video_name, '✓', csv_file)
                        continue
                    else:
                        print(f"重新下载 {video_name} (文件不完整)")
                        # 删除不完整的目录
                        try:
                            shutil.rmtree(video_folder)
                        except Exception:
                            pass
                
                # 下载视频
                if download_single_video(video_name, cache_dir):
                    success_list.append(video_name)
                    # 立即更新CSV状态为成功
                    update_single_video_status(video_name, '✓', csv_file)
                    print(f"✓ {video_name} 已更新状态")
                else:
                    failed_list.append(video_name)
                    # 立即更新CSV状态为异常
                    update_single_video_status(video_name, '下载异常', csv_file)
                    
            except KeyboardInterrupt:
                # 处理Ctrl+C中断
                print(f"\n\n用户中断下载！")
                print(f"正在处理中断的视频: {video_name}")
                
                # 将当前正在下载的视频标记为异常
                failed_list.append(video_name)
                update_single_video_status(video_name, '下载异常', csv_file)
                
                # 清理可能的不完整文件
                video_folder = os.path.join(cache_dir, video_name)
                if os.path.exists(video_folder):
                    try:
                        shutil.rmtree(video_folder)
                        print(f"已清理不完整的文件: {video_name}")
                    except Exception as e:
                        print(f"清理文件失败: {e}")
                
                # 重新抛出中断，让外层处理
                raise
                
            except Exception as e:
                # 处理其他异常
                print(f"下载 {video_name} 时发生异常: {e}")
                failed_list.append(video_name)
                update_single_video_status(video_name, '下载异常', csv_file)
        
    except KeyboardInterrupt:
        print(f"\n\n下载被用户中断")
        print(f"已处理: 成功 {len(success_list)} 个, 失败 {len(failed_list)} 个")
        return success_list, failed_list
    
    # 显示下载结果
    print("\n" + "="*50)
    print(f"{description}下载完成")
    print(f"成功: {len(success_list)}个")
    print(f"失败: {len(failed_list)}个")
    
    if failed_list:
        print("\n失败的视频:")
        for video in failed_list:
            print(f"  - {video}")
    
    return success_list, failed_list


def download_failed_videos(cache_dir: str, csv_file: str):
    """重新下载之前失败的视频"""
    # 读取失败的视频列表
    failed_videos = get_failed_videos_from_csv(csv_file)
    
    if not failed_videos:
        print("没有找到下载异常的视频")
        return
    
    print(f"找到 {len(failed_videos)} 个下载异常的视频:")
    for video in failed_videos[:5]:  # 只显示前5个
        print(f"  - {video}")
    if len(failed_videos) > 5:
        print(f"  ... 还有 {len(failed_videos) - 5} 个")
    
    # 确认下载
    confirm = input(f"\n确认重新下载这 {len(failed_videos)} 个视频吗? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("取消下载")
        return
    
    # 开始下载 - 状态会即时更新，不需要再调用update_csv_after_download
    success_list, failed_list = download_videos_batch(failed_videos, cache_dir, "异常的视频")
    
    print(f"\n重新下载完成: 成功 {len(success_list)} 个, 失败 {len(failed_list)} 个")


def clear_pick_now_marks(csv_file: str) -> None:
    """清除CSV文件中所有的pick_now标记"""
    if not os.path.exists(csv_file):
        return
    
    try:
        # 读取现有CSV数据
        rows = []
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                row['pick_now'] = ''  # 清除pick_now标记
                rows.append(row)
        
        # 写回CSV文件
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            if rows:
                fieldnames = ['video_name', 'status', 'pick_now']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(rows)
        
    except Exception as e:
        print(f"警告: 清除pick_now标记时出错: {e}")


def download_selected_videos(cache_dir: str, csv_file: str):
    """下载选中的视频源"""
    # 读取选中的视频
    selected_videos = read_selected_videos_from_csv(csv_file)
    
    if not selected_videos:
        print("没有找到选中的视频")
        print("请编辑CSV文件的'pick_now'列，在需要下载的视频行填入 'x' 或 '1'")
        return
    
    print(f"找到 {len(selected_videos)} 个选中的视频:")
    for video in selected_videos[:5]:  # 只显示前5个
        print(f"  - {video}")
    if len(selected_videos) > 5:
        print(f"  ... 还有 {len(selected_videos) - 5} 个")
    
    # 确认下载
    confirm = input(f"\n确认下载这 {len(selected_videos)} 个视频吗? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("取消下载")
        return
    
    # 开始下载 - 状态会即时更新，不需要再调用update_csv_after_download
    success_list, failed_list = download_videos_batch(selected_videos, cache_dir, "选中的视频")
    
    # 清除所有pick_now标记
    clear_pick_now_marks(csv_file)
    
    print(f"\n下载完成: 成功 {len(success_list)} 个, 失败 {len(failed_list)} 个")


def download_all_missing_videos(missing_videos: List[str], cache_dir: str, csv_file: str):
    """下载所有缺失的视频源"""
    if not missing_videos:
        print("所有视频都已存在，无需下载")
        return
    
    print(f"找到 {len(missing_videos)} 个缺失的视频")
    
    # 显示缺失视频的类型统计
    type_count = {}
    for video in missing_videos:
        video_type = get_video_type(video)
        type_count[video_type] = type_count.get(video_type, 0) + 1
    
    print("缺失视频类型统计:")
    for video_type, count in type_count.items():
        print(f"  - {video_type}: {count}个")
    
    # 确认下载
    confirm = input(f"\n确认下载所有 {len(missing_videos)} 个缺失视频吗? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("取消下载")
        return
    
    # 开始下载 - 状态会即时更新，不需要再调用update_csv_after_download
    success_list, failed_list = download_videos_batch(missing_videos, cache_dir, "缺失的视频")
    
    print(f"\n下载完成: 成功 {len(success_list)} 个, 失败 {len(failed_list)} 个")


def main():
    """主函数"""
    # 配置路径
    qa_dir = "./data"  # QA文件目录
    cache_dir = "./static/videos"  # 视频缓存目录
    output_csv = "./video_download_status.csv"  # 输出CSV文件
    
    # 扫描QA文件获取video_name
    video_names = scan_qa_files(qa_dir)
    
    while True:
        print("\n" + "="*50)
        print("视频文件管理工具")
        print("="*50)
        print("1. 统计本地视频信息")
        print("2. 下载视频")
        print("0. 退出")
        
        choice = input("请输入选择 (0/1/2): ").strip()
        
        if choice == "0":
            print("退出程序")
            break
        elif choice == "1":
            show_statistics(video_names, cache_dir, output_csv)
        elif choice == "2":
            # 检查缺失的视频
            results = check_local_videos(video_names, cache_dir)
            missing_videos = [name for name in video_names if not results[name]]
            
            while True:
                print("\n" + "-"*30)
                print("下载选项")
                print("-"*30)
                print("1. 下载选中视频源")
                print("2. 下载所有缺失视频源")
                print("3. 重新下载异常视频")
                print("0. 返回主菜单")
                
                download_choice = input("请输入选择 (0/1/2/3): ").strip()
                
                if download_choice == "0":
                    break
                elif download_choice == "1":
                    download_selected_videos(cache_dir, output_csv)
                elif download_choice == "2":
                    download_all_missing_videos(missing_videos, cache_dir, output_csv)
                elif download_choice == "3":
                    download_failed_videos(cache_dir, output_csv)
                else:
                    print("无效选择，请重新输入")
        else:
            print("无效选择，请重新输入")


if __name__ == "__main__":
    main()

